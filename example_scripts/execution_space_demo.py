#!/usr/bin/env python3
"""
æ‰§è¡Œç©ºé—´æ¼”ç¤ºè„šæœ¬
ç”¨äºæµ‹è¯•æ¯æ¬¡æ‰§è¡Œçš„ç‹¬ç«‹ç©ºé—´éš”ç¦»
"""
import os
import json
import argparse
from datetime import datetime

print("=" * 70)
print("  ğŸ“¦ æ‰§è¡Œç©ºé—´éš”ç¦»æ¼”ç¤º")
print("=" * 70)

# è·å–å½“å‰å·¥ä½œç›®å½•
cwd = os.getcwd()
print(f"\nå½“å‰å·¥ä½œç›®å½•: {cwd}")
print(f"æ‰§è¡Œç©ºé—´ID: {os.path.basename(cwd)}")

# åˆ—å‡ºæ‰§è¡Œç©ºé—´ä¸­çš„æ‰€æœ‰æ–‡ä»¶
print(f"\nğŸ“‹ æ‰§è¡Œç©ºé—´å†…å®¹:")
files = os.listdir('.')
if files:
    for i, filename in enumerate(files, 1):
        file_path = os.path.join('.', filename)
        size = os.path.getsize(file_path)
        print(f"  [{i}] ğŸ“„ {filename} ({size} å­—èŠ‚)")
else:
    print("  (ç©º)")

# å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
parser = argparse.ArgumentParser()
parser.add_argument('--files', type=str, help='ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨(JSONæ ¼å¼)')
args = parser.parse_args()

if args.files:
    file_list = json.loads(args.files)
    print(f"\nğŸ“¤ å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ (å…± {len(file_list)} ä¸ª):")

    for i, filename in enumerate(file_list, 1):
        if os.path.exists(filename):
            size = os.path.getsize(filename)
            print(f"\n[{i}] ğŸ“„ {filename}")
            print(f"    å¤§å°: {size} å­—èŠ‚")

            # è¯»å–å¹¶æ˜¾ç¤ºæ–‡ä»¶å†…å®¹å‰5è¡Œ
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:5]
                    if lines:
                        print(f"    å†…å®¹é¢„è§ˆ (å‰{len(lines)}è¡Œ):")
                        for line in lines:
                            print(f"      {line.rstrip()}")
            except:
                print("    (äºŒè¿›åˆ¶æ–‡ä»¶æˆ–æ— æ³•è¯»å–)")
else:
    print("\nğŸ“¤ æœªä¸Šä¼ æ–‡ä»¶")

# åˆ›å»ºä¸€ä¸ªè¾“å‡ºæ–‡ä»¶
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
output_filename = f'output_{timestamp}.txt'

print(f"\nğŸ“ åˆ›å»ºè¾“å‡ºæ–‡ä»¶: {output_filename}")
with open(output_filename, 'w', encoding='utf-8') as f:
    f.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().isoformat()}\n")
    f.write(f"æ‰§è¡Œç©ºé—´: {cwd}\n")
    f.write(f"æ‰§è¡Œç©ºé—´ID: {os.path.basename(cwd)}\n")
    f.write("\nè¿™æ˜¯è„šæœ¬æ‰§è¡Œç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶\n")
    f.write("æ¯æ¬¡æ‰§è¡Œéƒ½ä¼šåœ¨ç‹¬ç«‹çš„æ‰§è¡Œç©ºé—´ä¸­åˆ›å»ºæ­¤æ–‡ä»¶\n")
    f.write("ä¸åŒçš„æ‰§è¡Œäº’ä¸å½±å“\n")

print(f"âœ… æ–‡ä»¶å·²åˆ›å»º: {output_filename}")

# åˆ›å»ºå­ç›®å½•å’Œæ–‡ä»¶
subdir = 'results'
os.makedirs(subdir, exist_ok=True)
print(f"\nğŸ“ åˆ›å»ºå­ç›®å½•: {subdir}/")

result_file = os.path.join(subdir, f'result_{timestamp}.json')
with open(result_file, 'w', encoding='utf-8') as f:
    json.dump({
        'execution_time': datetime.now().isoformat(),
        'workspace': cwd,
        'workspace_id': os.path.basename(cwd),
        'status': 'success',
        'message': 'è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ‰§è¡Œç©ºé—´'
    }, f, indent=2, ensure_ascii=False)

print(f"âœ… ç»“æœæ–‡ä»¶å·²åˆ›å»º: {result_file}")

# å†æ¬¡åˆ—å‡ºæ‰§è¡Œç©ºé—´ä¸­çš„æ‰€æœ‰æ–‡ä»¶
print(f"\nğŸ“‹ æ‰§è¡Œåçš„æ‰§è¡Œç©ºé—´å†…å®¹:")
for root, dirs, files in os.walk('.'):
    level = root.replace('.', '').count(os.sep)
    indent = '  ' * level
    print(f"{indent}ğŸ“ {os.path.basename(root)}/")
    sub_indent = '  ' * (level + 1)
    for file in files:
        file_path = os.path.join(root, file)
        size = os.path.getsize(file_path)
        print(f"{sub_indent}ğŸ“„ {file} ({size} å­—èŠ‚)")

print("\n" + "=" * 70)
print("âœ… æ‰§è¡Œå®Œæˆ!")
print("=" * 70)
print("\nğŸ’¡ æç¤º:")
print("   - æ¯æ¬¡æ‰§è¡Œéƒ½æœ‰ç‹¬ç«‹çš„æ‰§è¡Œç©ºé—´")
print("   - ä¸Šä¼ çš„æ–‡ä»¶åªåœ¨å½“å‰æ‰§è¡Œç©ºé—´å¯è§")
print("   - è¾“å‡ºçš„æ–‡ä»¶ä¿å­˜åœ¨å½“å‰æ‰§è¡Œç©ºé—´")
print("   - å¤šæ¬¡æ‰§è¡ŒåŒä¸€è„šæœ¬,å„æ‰§è¡Œç©ºé—´å®Œå…¨éš”ç¦»")
print("=" * 70)
